--- ead.rb	2021-07-15 02:50:11.058221983 -0400
+++ nyu_ead_exporter.rb	2021-07-21 20:02:56.593290941 -0400
@@ -1,4 +1,3 @@
-# encoding: utf-8
 require 'nokogiri'
 require 'securerandom'
 require 'cgi'
@@ -104,9 +103,9 @@
   # https://www.xml.com/pub/a/2001/07/25/namingparts.html
   # https://razzed.com/2009/01/30/valid-characters-in-attribute-names-in-htmlxml/
 
-  def add_xlink_prefix(content)
+  def add_ns2_prefix(content)
     %w{ actuate arcrole entityref from href id linktype parent role show target title to xpointer }.each do |xa|
-      content.gsub!(/ #{xa}=/) {|match| " xlink:#{match.strip}"} if content =~ / #{xa}=/
+      content.gsub!(/ #{xa}=/) {|match| " ns2:#{match.strip}"} if content =~ / #{xa}=/
     end
     content
   end
@@ -130,7 +129,7 @@
     # xlink added so only do this processing if the element is there
     # attribute check is inside the add_xlink_prefix method
     xlink_eles = %w{ arc archref bibref extptr extptrloc extref extrefloc linkgrp ptr ptrloc ref refloc resource title }
-    content = add_xlink_prefix(content) if xlink_eles.any? { |word| content =~ /<#{word}\s/ }
+    content = add_ns2_prefix(content) if xlink_eles.any? { |word| content =~ /<#{word}\s/ }
 
     begin
       if ASpaceExport::Utils.has_html?(content)
@@ -144,6 +143,7 @@
   end
 
   def stream(data)
+    @xlink_namespace = "ns2"
     @stream_handler = ASpaceExport::StreamHandler.new
     @fragments = ASpaceExport::RawXMLHandler.new
     @include_unpublished = data.include_unpublished?
@@ -152,10 +152,12 @@
     @id_prefix = I18n.t('archival_object.ref_id_export_prefix', :default => 'aspace_')
 
     doc = Nokogiri::XML::Builder.new(:encoding => "UTF-8") do |xml|
+      begin
+
       ead_attributes = {
         'xmlns:xsi' => 'http://www.w3.org/2001/XMLSchema-instance',
         'xsi:schemaLocation' => 'urn:isbn:1-931666-22-9 http://www.loc.gov/ead/ead.xsd',
-        'xmlns:xlink' => 'http://www.w3.org/1999/xlink'
+        'xmlns:ns2' => 'http://www.w3.org/1999/xlink'
       }
 
       if data.publish === false
@@ -170,12 +172,19 @@
 })
 
         atts = {:level => data.level, :otherlevel => data.other_level}
+
         atts.reject! {|k, v| v.nil?}
 
         xml.archdesc(atts) {
 
+
+
           xml.did {
 
+                    if (languages = data.lang_materials)
+                      serialize_languages(languages, xml, @fragments)
+                    end
+
             if (val = data.repo.name)
               xml.repository {
                 xml.corpname { sanitize_mixed_content(val, xml, @fragments) }
@@ -202,14 +211,12 @@
 
             serialize_did_notes(data, xml, @fragments)
 
-            if (languages = data.lang_materials)
-              serialize_languages(languages, xml, @fragments)
-            end
 
             data.instances_with_sub_containers.each do |instance|
               serialize_container(instance, xml, @fragments)
             end
 
+
             EADSerializer.run_serialize_step(data, xml, @fragments, :did)
 
           }# </did>
@@ -240,235 +247,132 @@
           }
         }
       }
-    end
-    doc.doc.root.add_namespace nil, 'urn:isbn:1-931666-22-9'
 
-    Enumerator.new do |y|
-      @stream_handler.stream_out(doc, @fragments, y)
-    end
+            rescue => e
+              xml.text  "ASPACE EXPORT ERROR : YOU HAVE A PROBLEM WITH YOUR EXPORT OF YOUR RESOURCE. THE FOLLOWING INFORMATION MAY HELP:\n
+              MESSAGE: #{e.message.inspect}  \n
+              TRACE: #{e.backtrace.inspect} \n "
   end
 
-  # this extracts <head> content and returns it. optionally, you can provide a
-  # backup text node that will be returned if there is no <head> nodes in the
-  # content
-  def extract_head_text(content, backup = "")
-    content ||= ""
-    match = content.strip.match(/<head( [^<>]+)?>(.+?)<\/head>/)
-    if match.nil? # content has no head so we return it as it
-      return [content, backup ]
-    else
-      [ content.gsub(match.to_a.first, ''), match.to_a.last]
-    end
-  end
-
-  def serialize_child(data, xml, fragments, c_depth = 1)
-    return if data["publish"] === false && !@include_unpublished
-    return if data["suppressed"] === true
-
-    tag_name = @use_numbered_c_tags ? :"c#{c_depth.to_s.rjust(2, '0')}" : :c
-
-    atts = {:level => data.level, :otherlevel => data.other_level, :id => prefix_id(data.ref_id)}
 
-    if data.publish === false
-      atts[:audience] = 'internal'
-    end
 
-    atts.reject! {|k, v| v.nil?}
-    xml.send(tag_name, atts) {
-
-      xml.did {
-        if (val = data.title)
-          xml.unittitle { sanitize_mixed_content( val, xml, fragments) }
         end
+          doc.doc.root.add_namespace nil, 'urn:isbn:1-931666-22-9'
 
-        if AppConfig[:arks_enabled]
-          ark_url = ArkName::get_ark_url(data.id, :archival_object)
-          if ark_url
-            xml.unitid {
-              xml.extref ({"xlink:href" => ark_url,
-                           "xlink:actuate" => "onLoad",
-                           "xlink:show" => "new",
-                           "xlink:type" => "simple"
-                          }) { xml.text 'Archival Resource Key' }
-            }
-          end
+          Enumerator.new do |y|
+            @stream_handler.stream_out(doc, @fragments, y)
         end
 
-        if !data.component_id.nil? && !data.component_id.empty?
-          xml.unitid data.component_id
-        end
 
-        if @include_unpublished
-          data.external_ids.each do |exid|
-            xml.unitid ({ "audience" => "internal", "type" => exid['source'], "identifier" => exid['external_id']}) { xml.text exid['external_id']}
-          end
         end
 
-        serialize_origination(data, xml, fragments)
-        serialize_extents(data, xml, fragments)
-        serialize_dates(data, xml, fragments)
-        serialize_did_notes(data, xml, fragments)
+        def serialize_did_notes(data, xml, fragments)
+          data.notes.each do |note|
+            next if note["publish"] === false && !@include_unpublished
+            next unless data.did_note_types.include?(note['type']) # && note["publish"] == true)
 
-        if (languages = data.lang_materials)
-          serialize_languages(languages, xml, fragments)
-        end
+            #audatt = note["publish"] === false ? {:audience => 'internal'} : {}
+            content = ASpaceExport::Utils.extract_note_text(note, @include_unpublished)
 
-        EADSerializer.run_serialize_step(data, xml, fragments, :did)
+            att = { :id => prefix_id(note['persistent_id']) }.reject {|k,v| v.nil? || v.empty? || v == "null" }
+            att ||= {}
 
-        data.instances_with_sub_containers.each do |instance|
-          serialize_container(instance, xml, @fragments)
+            case note['type']
+            when 'dimensions', 'physfacet'
+              #xml.physdesc(audatt) {
+              xml.physdesc {
+                generate_xml(content, xml, fragments, note['type'], att)
+              }
+            else
+              #att.merge!(audatt)
+              if note['type'] == 'langmaterial'
+                label = { :label => "Language of Materials note" }
+                att.merge!(label)
         end
-
-        if @include_daos
-          data.instances_with_digital_objects.each do |instance|
-            serialize_digital_object(instance['digital_object']['_resolved'], xml, fragments)
+              generate_xml(content, xml, fragments, note['type'], att)
           end
         end
-      }
-
-      serialize_nondid_notes(data, xml, fragments)
-
-      serialize_bibliographies(data, xml, fragments)
-
-      serialize_indexes(data, xml, fragments)
-
-      serialize_controlaccess(data, xml, fragments)
-
-      EADSerializer.run_serialize_step(data, xml, fragments, :archdesc)
-
-      data.children_indexes.each do |i|
-        xml.text(
-          @stream_handler.buffer {|xml, new_fragments|
-            serialize_child(data.get_child(i), xml, new_fragments, c_depth + 1)
-          }
-        )
-      end
-    }
   end
 
-
-  def serialize_origination(data, xml, fragments)
-    unless data.creators_and_sources.nil?
-      data.creators_and_sources.each do |link|
-        agent = link['_resolved']
-        published = agent['publish'] === true
-
-        next if !published && !@include_unpublished
-
-        link['role'] == 'creator' ? role = link['role'].capitalize : role = link['role']
-        relator = link['relator']
-        sort_name = agent['display_name']['sort_name']
-        rules = agent['display_name']['rules']
-        source = agent['display_name']['source']
-        authfilenumber = agent['display_name']['authority_id']
-        node_name = case agent['agent_type']
-                    when 'agent_person'; 'persname'
-                    when 'agent_family'; 'famname'
-                    when 'agent_corporate_entity'; 'corpname'
-                    when 'agent_software'; 'name'
-                    end
-
-        origination_attrs = {:label => role}
-        origination_attrs[:audience] = 'internal' unless published
-        xml.origination(origination_attrs) {
-          atts = {:role => relator, :source => source, :rules => rules, :authfilenumber => authfilenumber}
-          atts.reject! {|k, v| v.nil?}
-
-          xml.send(node_name, atts) {
-            sanitize_mixed_content(sort_name, xml, fragments )
-          }
+        def generate_xml(content, xml, fragments, node, attributes)
+          xml.send(node, attributes) {
+            sanitize_mixed_content(content, xml, fragments,ASpaceExport::Utils.include_p?(node))
         }
       end
-    end
+
+        def customize_ead_data(custom_text,data)
+          custom_text + data
   end
 
-  def serialize_controlaccess(data, xml, fragments)
-    if (data.controlaccess_subjects.length + data.controlaccess_linked_agents.length) > 0
-      xml.controlaccess {
-        data.controlaccess_subjects.each do |node_data|
-          xml.send(node_data[:node_name], node_data[:atts]) {
-            sanitize_mixed_content( node_data[:content], xml, fragments, ASpaceExport::Utils.include_p?(node_data[:node_name]) )
-          }
+        def upcase_initial_char(string)
+          reformat_string = string
+          get_match = /(^[a-z])(.*)/.match(string)
+          if get_match
+            reformat_string = get_match[1].upcase + get_match[2]
+          end
+          reformat_string
         end
 
-        data.controlaccess_linked_agents.each do |node_data|
-          xml.send(node_data[:node_name], node_data[:atts]) {
-            sanitize_mixed_content( node_data[:content], xml, fragments, ASpaceExport::Utils.include_p?(node_data[:node_name]) )
+        def serialize_nondid_notes(data, xml, fragments)
+          data.notes.each do |note|
+            next if note["publish"] === false && !@include_unpublished
+            next if note['internal']
+            next if note['type'].nil?
+            next unless data.archdesc_note_types.include?(note['type']) # and note["publish"] == true)
+            if note['type'] == 'legalstatus'
+              xml.accessrestrict {
+                serialize_note_content(note, xml, fragments)
           }
+            else
+              serialize_note_content(note, xml, fragments)
         end
-      } #</controlaccess>
     end
   end
 
-  def serialize_subnotes(subnotes, xml, fragments, include_p = true)
-    subnotes.each do |sn|
-      next if sn["publish"] === false && !@include_unpublished
-
-      audatt = sn["publish"] === false ? {:audience => 'internal'} : {}
-
-      title = sn['title']
+        #not sure if I should do this
+        def serialize_did_notes(data, xml, fragments)
+          data.notes.each do |note|
+            next if note["publish"] === false && !@include_unpublished
+            next unless data.did_note_types.include?(note['type']) # and note["publish"] == true)
 
-      case sn['jsonmodel_type']
-      when 'note_text'
-        sanitize_mixed_content(sn['content'], xml, fragments, include_p )
-      when 'note_chronology'
-        xml.chronlist(audatt) {
-          xml.head { sanitize_mixed_content(title, xml, fragments) } if title
+            audatt = note["publish"] === false ? {:audience => 'internal'} : {}
+            content = ASpaceExport::Utils.extract_note_text(note, @include_unpublished)
 
-          sn['items'].each do |item|
-            xml.chronitem {
-              if (val = item['event_date'])
-                xml.date { sanitize_mixed_content( val, xml, fragments) }
-              end
-              if item['events'] && !item['events'].empty?
-                xml.eventgrp {
-                  item['events'].each do |event|
-                    xml.event { sanitize_mixed_content(event, xml, fragments) }
-                  end
-                }
-              end
-            }
-          end
-        }
-      when 'note_orderedlist'
-        atts = {:type => 'ordered', :numeration => sn['enumeration']}.reject {|k, v| v.nil? || v.empty? || v == "null" }.merge(audatt)
-        xml.list(atts) {
-          xml.head { sanitize_mixed_content(title, xml, fragments) } if title
+            att = { :id => prefix_id(note['persistent_id']) }.reject {|k,v| v.nil? || v.empty? || v == "null" }
+            att ||= {}
 
-          sn['items'].each do |item|
-            xml.item { sanitize_mixed_content(item, xml, fragments)}
-          end
+            case note['type']
+            when 'dimensions', 'physfacet'
+              xml.physdesc(audatt) {
+              #xml.physdesc {
+                xml.send(note['type'], att) {
+                  sanitize_mixed_content( content, xml, fragments, ASpaceExport::Utils.include_p?(note['type'])  )
         }
-      when 'note_definedlist'
-        xml.list({:type => 'deflist'}.merge(audatt)) {
-          xml.head { sanitize_mixed_content(title, xml, fragments) } if title
-
-          sn['items'].each do |item|
-            xml.defitem {
-              xml.label { sanitize_mixed_content(item['label'], xml, fragments) } if item['label']
-              xml.item { sanitize_mixed_content(item['value'], xml, fragments )} if item['value']
             }
-          end
+            else
+              xml.send(note['type'], att) {
+                sanitize_mixed_content(content, xml, fragments,ASpaceExport::Utils.include_p?(note['type']))
         }
       end
     end
   end
 
-
   def serialize_container(inst, xml, fragments)
+          containers = []
     atts = {}
-
     sub = inst['sub_container']
     top = sub['top_container']['_resolved']
 
     atts[:id] = prefix_id(SecureRandom.hex)
+          parent_id = atts[:id]
     last_id = atts[:id]
 
-    atts[:type] = top['type']
+          atts[:type] =  upcase_initial_char(top['type'])
+
     text = top['indicator']
 
-    atts[:label] = I18n.t("enumerations.instance_instance_type.#{inst['instance_type']}",
-                          :default => inst['instance_type'])
+          atts[:label] = upcase_initial_char(I18n.t("enumerations.instance_instance_type.#{inst['instance_type']}",
+            :default => inst['instance_type']))
     atts[:label] << " [#{top['barcode']}]" if top['barcode']
 
     if (cp = top['container_profile'])
@@ -476,48 +380,32 @@
     end
 
     xml.container(atts) {
+
       sanitize_mixed_content(text, xml, fragments)
     }
 
     (2..3).each do |n|
       atts = {}
-
       next unless sub["type_#{n}"]
-
-      atts[:id] = prefix_id(SecureRandom.hex)
-      atts[:parent] = last_id
-      last_id = atts[:id]
-
-      atts[:type] = sub["type_#{n}"]
+              atts[:parent] = parent_id
+              atts[:type] =  upcase_initial_char(sub["type_#{n}"])
       text = sub["indicator_#{n}"]
 
       xml.container(atts) {
         sanitize_mixed_content(text, xml, fragments)
       }
-    end
-  end
 
-  def is_digital_object_published?(digital_object, file_version = nil)
-    if !digital_object['publish']
-      return false
-    elsif !file_version.nil? and !file_version['publish']
-      return false
-    else
-      return true
     end
   end
-
   def serialize_digital_object(digital_object, xml, fragments)
     return if digital_object["publish"] === false && !@include_unpublished
     return if digital_object["suppressed"] === true
 
-    # ANW-285: Only serialize file versions that are published, unless include_unpublished flag is set
-    file_versions_to_display = digital_object['file_versions'].select {|fv| fv['publish'] == true || @include_unpublished }
-
+            file_versions = digital_object['file_versions']
     title = digital_object['title']
     date = digital_object['dates'][0] || {}
 
-    atts = {}
+            atts = digital_object["publish"] === false ? {:audience => 'internal'} : {}
 
     content = ""
     content << title if title
@@ -530,42 +418,38 @@
         content << "-#{date['end']}"
       end
     end
-    atts['xlink:title'] = digital_object['title'] if digital_object['title']
+            atts[@xlink_namespace+':title'] = digital_object['title'] if digital_object['title']
 
 
-    if file_versions_to_display.empty?
-      atts['xlink:type'] = 'simple'
-      atts['xlink:href'] = digital_object['digital_object_id']
-      atts['xlink:actuate'] = 'onRequest'
-      atts['xlink:show'] = 'new'
-      atts['audience'] = 'internal' unless is_digital_object_published?(digital_object)
+            if file_versions.empty?
+              atts[@xlink_namespace+':type'] = 'simple'
+              atts[@xlink_namespace+':href'] = digital_object['digital_object_id']
+              atts[@xlink_namespace+':actuate'] = 'onRequest'
+              atts[@xlink_namespace+':show'] = 'new'
       xml.dao(atts) {
         xml.daodesc { sanitize_mixed_content(content, xml, fragments, true) } if content
       }
-    elsif file_versions_to_display.length == 1
-      file_version = file_versions_to_display.first
+            elsif file_versions.length == 1
+              use = file_versions.first['use_statement'] if file_versions.first['use_statement']
+              atts[@xlink_namespace+':type'] = 'simple'
+              atts[@xlink_namespace+':href'] = file_versions.first['file_uri'] || digital_object['digital_object_id']
+              atts[@xlink_namespace+':actuate'] = file_versions.first['xlink_actuate_attribute'] || 'onRequest'
+              atts[@xlink_namespace+':show'] = file_versions.first['xlink_show_attribute'] || 'new'
+              atts[@xlink_namespace+':role'] = I18n.t("enumerations.file_version_use_statement.#{use}") if use
 
-      atts['xlink:type'] = 'simple'
-      atts['xlink:actuate'] = file_version['xlink_actuate_attribute'] || 'onRequest'
-      atts['xlink:show'] = file_version['xlink_show_attribute'] || 'new'
-      atts['xlink:role'] = file_version['use_statement'] if file_version['use_statement']
-      atts['xlink:href'] = file_version['file_uri']
-      atts['audience'] = 'internal' unless is_digital_object_published?(digital_object, file_version)
       xml.dao(atts) {
         xml.daodesc { sanitize_mixed_content(content, xml, fragments, true) } if content
       }
     else
-      atts['xlink:type'] = 'extended'
-      atts['audience'] = 'internal' unless is_digital_object_published?(digital_object)
-      xml.daogrp( atts ) {
+              xml.daogrp( atts.merge( { @xlink_namespace+':type' => 'extended'} ) ) {
         xml.daodesc { sanitize_mixed_content(content, xml, fragments, true) } if content
-        file_versions_to_display.each do |file_version|
-          atts = {}
-          atts['xlink:type'] = 'locator'
-          atts['xlink:href'] = file_version['file_uri']
-          atts['xlink:role'] = file_version['use_statement'] if file_version['use_statement']
-          atts['xlink:title'] = file_version['caption'] if file_version['caption']
-          atts['audience'] = 'internal' unless is_digital_object_published?(digital_object, file_version)
+                file_versions.each do |file_version|
+                  use = file_versions.first['use_statement'] if file_versions.first['use_statement']
+                  atts[@xlink_namespace+':type'] = 'locator'
+                  atts[@xlink_namespace+':href'] = file_version['file_uri'] || digital_object['digital_object_id']
+                  atts[@xlink_namespace+':role'] = file_version['use_statement'] if file_version['use_statement']
+                  atts[@xlink_namespace+':title'] = file_version['caption'] if file_version['caption']
+                  atts['ns2:role'] = I18n.t("enumerations.file_version_use_statement.#{use}") if use
           xml.daoloc(atts)
         end
       }
@@ -573,233 +457,79 @@
   end
 
 
-  def serialize_extents(obj, xml, fragments)
-    if obj.extents.length
-      obj.extents.each do |e|
-        next if e["publish"] === false && !@include_unpublished
-        audatt = e["publish"] === false ? {:audience => 'internal'} : {}
-        xml.physdesc({:altrender => e['portion']}.merge(audatt)) {
-          if e['number'] && e['extent_type']
-            xml.extent({:altrender => 'materialtype spaceoccupied'}) {
-              sanitize_mixed_content("#{e['number']} #{I18n.t('enumerations.extent_extent_type.'+e['extent_type'], :default => e['extent_type'])}", xml, fragments)
-            }
-          end
-          if e['container_summary']
-            xml.extent({:altrender => 'carrier'}) {
-              sanitize_mixed_content( e['container_summary'], xml, fragments)
-            }
-          end
-          xml.physfacet { sanitize_mixed_content(e['physical_details'], xml, fragments) } if e['physical_details']
-          xml.dimensions  { sanitize_mixed_content(e['dimensions'], xml, fragments) } if e['dimensions']
-        }
-      end
-    end
-  end
+          def serialize_child(data, xml, fragments, c_depth = 1)
+            begin
+              return if data["publish"] === false && !@include_unpublished
+              return if data["supressed"] === true
+              tag_name = @use_numbered_c_tags ? :"c#{c_depth.to_s.rjust(2, '0')}" : :c
 
+              atts = {:level => data.level, :otherlevel => data.other_level, :id => prefix_id(data.ref_id)}
 
-  def serialize_dates(obj, xml, fragments)
-    obj.archdesc_dates.each do |node_data|
-      next if node_data["publish"] === false && !@include_unpublished
-      audatt = node_data["publish"] === false ? {:audience => 'internal'} : {}
-      xml.unitdate(node_data[:atts].merge(audatt)) {
-        sanitize_mixed_content( node_data[:content], xml, fragments )
-      }
-    end
+              if data.publish === false
+                atts[:audience] = 'internal'
   end
 
+              atts.reject! {|k, v| v.nil?}
+              xml.send(tag_name, atts) {
 
-  def serialize_did_notes(data, xml, fragments)
-    data.notes.each do |note|
-      next if note["publish"] === false && !@include_unpublished
-      next unless data.did_note_types.include?(note['type'])
-
-      audatt = note["publish"] === false ? {:audience => 'internal'} : {}
-      content = ASpaceExport::Utils.extract_note_text(note, @include_unpublished)
-
-      att = { :id => prefix_id(note['persistent_id']) }.reject {|k, v| v.nil? || v.empty? || v == "null" }
-      att ||= {}
-
-      case note['type']
-      when 'dimensions', 'physfacet'
-        att[:label] = note['label'] if note['label']
-        xml.physdesc(audatt) {
-          xml.send(note['type'], att) {
-            sanitize_mixed_content( content, xml, fragments, ASpaceExport::Utils.include_p?(note['type']) )
-          }
-        }
-      when 'physdesc'
-        att[:label] = note['label'] if note['label']
-        xml.send(note['type'], att.merge(audatt)) {
-          sanitize_mixed_content(content, xml, fragments, ASpaceExport::Utils.include_p?(note['type']))
-        }
-      else
-        xml.send(note['type'], att.merge(audatt)) {
-          sanitize_mixed_content(content, xml, fragments, ASpaceExport::Utils.include_p?(note['type']))
-        }
-      end
-    end
+                xml.did {
+                  if (val = data.title)
+                    xml.unittitle {  sanitize_mixed_content( val,xml, fragments) }
   end
 
-  def serialize_languages(languages, xml, fragments)
-    lm = []
-    language_notes = languages.map {|l| l['notes']}.compact.reject {|e| e == [] }.flatten
-    if !language_notes.empty?
-      language_notes.each do |note|
-        unless note["publish"] === false && !@include_unpublished
-          audatt = note["publish"] === false ? {:audience => 'internal'} : {}
-          content = ASpaceExport::Utils.extract_note_text(note, @include_unpublished)
-
-          att = { :id => prefix_id(note['persistent_id']) }.reject {|k, v| v.nil? || v.empty? || v == "null" }
-          att ||= {}
-
-          xml.send(note['type'], att.merge(audatt)) {
-            sanitize_mixed_content(content, xml, fragments, ASpaceExport::Utils.include_p?(note['type']))
-          }
-          lm << note
-        end
-      end
-      if lm == []
-        languages = languages.map {|l| l['language_and_script']}.compact
-        xml.langmaterial {
-          languages.map {|language|
-            punctuation = language.equal?(languages.last) ? '.' : ', '
-            lang_translation = I18n.t("enumerations.language_iso639_2.#{language['language']}", :default => language['language'])
-            if language['script']
-              xml.language(:langcode => language['language'], :scriptcode => language['script']) {
-                xml.text(lang_translation)
-              }
-            else
-              xml.language(:langcode => language['language']) {
-                xml.text(lang_translation)
-              }
-            end
-            xml.text(punctuation)
-          }
-        }
-      end
-    # ANW-697: If no Language Text subrecords are available, the Language field translation values for each Language and Script subrecord should be exported, separated by commas, enclosed in <language> elements with associated @langcode and @scriptcode attribute values, and terminated by a period.
-    else
-      languages = languages.map {|l| l['language_and_script']}.compact
-      if !languages.empty?
-        xml.langmaterial {
-          languages.map {|language|
-            punctuation = language.equal?(languages.last) ? '.' : ', '
-            lang_translation = I18n.t("enumerations.language_iso639_2.#{language['language']}", :default => language['language'])
-            if language['script']
-              xml.language(:langcode => language['language'], :scriptcode => language['script']) {
-                xml.text(lang_translation)
-              }
-            else
-              xml.language(:langcode => language['language']) {
-                xml.text(lang_translation)
-              }
-            end
-            xml.text(punctuation)
-          }
-        }
+                  if !data.component_id.nil? && !data.component_id.empty?
+                    xml.unitid data.component_id
       end
+
+                  if @include_unpublished
+                    data.external_ids.each do |exid|
+                      xml.unitid  ({ "audience" => "internal",  "type" => exid['source'], "identifier" => exid['external_id']}) { xml.text exid['external_id']}
     end
   end
 
-  def serialize_note_content(note, xml, fragments)
-    return if note["publish"] === false && !@include_unpublished
-    audatt = note["publish"] === false ? {:audience => 'internal'} : {}
-    content = note["content"]
+                  serialize_origination(data, xml, fragments)
+                  serialize_extents(data, xml, fragments)
+                  serialize_dates(data, xml, fragments)
+                  serialize_did_notes(data, xml, fragments)
 
-    atts = {:id => prefix_id(note['persistent_id']) }.reject {|k, v| v.nil? || v.empty? || v == "null" }.merge(audatt)
+                  EADSerializer.run_serialize_step(data, xml, fragments, :did)
 
-    head_text = note['label'] ? note['label'] : I18n.t("enumerations._note_types.#{note['type']}", :default => note['type'])
-    content, head_text = extract_head_text(content, head_text)
-    xml.send(note['type'], atts) {
-      xml.head { sanitize_mixed_content(head_text, xml, fragments) } unless ASpaceExport::Utils.headless_note?(note['type'], content )
-      sanitize_mixed_content(content, xml, fragments, ASpaceExport::Utils.include_p?(note['type']) ) if content
-      if note['subnotes']
-        serialize_subnotes(note['subnotes'], xml, fragments, ASpaceExport::Utils.include_p?(note['type']))
+                  data.instances_with_sub_containers.each do |instance|
+                    serialize_container(instance, xml, @fragments)
       end
     }
-  end
-
-
-  def serialize_nondid_notes(data, xml, fragments)
-    data.notes.each do |note|
-      next if note["publish"] === false && !@include_unpublished
-      next if note['internal']
-      next if note['type'].nil?
-      next unless data.archdesc_note_types.include?(note['type'])
-      audatt = note["publish"] === false ? {:audience => 'internal'} : {}
-      if note['type'] == 'legalstatus'
-        xml.accessrestrict(audatt) {
-          serialize_note_content(note, xml, fragments)
-        }
-      else
-        serialize_note_content(note, xml, fragments)
-      end
+                if @include_daos
+                  data.instances_with_digital_objects.each do |instance|
+                    serialize_digital_object(instance['digital_object']['_resolved'], xml, fragments)
     end
   end
+                serialize_nondid_notes(data, xml, fragments)
 
+                serialize_bibliographies(data, xml, fragments)
 
-  def serialize_bibliographies(data, xml, fragments)
-    data.bibliographies.each do |note|
-      next if note["publish"] === false && !@include_unpublished
-      content = ASpaceExport::Utils.extract_note_text(note, @include_unpublished)
-      note_type = note["type"] ? note["type"] : "bibliography"
-      head_text = note['label'] ? note['label'] : I18n.t("enumerations._note_types.#{note_type}", :default => note_type )
-      audatt = note["publish"] === false ? {:audience => 'internal'} : {}
-
-      atts = {:id => prefix_id(note['persistent_id']) }.reject {|k, v| v.nil? || v.empty? || v == "null" }.merge(audatt)
+                serialize_indexes(data, xml, fragments)
 
-      xml.bibliography(atts) {
-        xml.head { sanitize_mixed_content(head_text, xml, fragments) }
-        sanitize_mixed_content( content, xml, fragments, true)
-        note['items'].each do |item|
-          xml.bibref { sanitize_mixed_content( item, xml, fragments) } unless item.empty?
-        end
-      }
-    end
-  end
+                serialize_controlaccess(data, xml, fragments)
 
+                EADSerializer.run_serialize_step(data, xml, fragments, :archdesc)
 
-  def serialize_indexes(data, xml, fragments)
-    data.indexes.each do |note|
-      next if note["publish"] === false && !@include_unpublished
-      audatt = note["publish"] === false ? {:audience => 'internal'} : {}
-      content = ASpaceExport::Utils.extract_note_text(note, @include_unpublished)
-      head_text = nil
-      if note['label']
-        head_text = note['label']
-      elsif note['type']
-        head_text = I18n.t("enumerations._note_types.#{note['type']}", :default => note['type'])
-      end
-      atts = {:id => prefix_id(note["persistent_id"]) }.reject {|k, v| v.nil? || v.empty? || v == "null" }.merge(audatt)
-
-      content, head_text = extract_head_text(content, head_text)
-      xml.index(atts) {
-        xml.head { sanitize_mixed_content(head_text, xml, fragments ) } unless head_text.nil?
-        sanitize_mixed_content(content, xml, fragments, true)
-        note['items'].each do |item|
-          next unless (node_name = data.index_item_type_map[item['type']])
-          xml.indexentry {
-            atts = item['reference'] ? {:target => prefix_id( item['reference']) } : {}
-            if (val = item['value'])
-              xml.send(node_name) { sanitize_mixed_content(val, xml, fragments )}
-            end
-            if (val = item['reference_text'])
-              xml.ref(atts) {
-                sanitize_mixed_content( val, xml, fragments)
-              }
-            end
+                data.children_indexes.each do |i|
+                  xml.text(
+                    @stream_handler.buffer {|xml, new_fragments|
+                      serialize_child(data.get_child(i), xml, new_fragments, c_depth + 1)
           }
+                  )
         end
       }
+            rescue => e
+              xml.text "ASPACE EXPORT ERROR : YOU HAVE A PROBLEM WITH YOUR EXPORT OF ARCHIVAL OBJECTS. THE FOLLOWING INFORMATION MAY HELP:\n
+
+              MESSAGE: #{e.message.inspect}  \n
+              TRACE: #{e.backtrace.inspect} \n "
     end
   end
 
-
   def serialize_eadheader(data, xml, fragments)
-    ark_url = AppConfig[:arks_enabled] ? ArkName::get_ark_url(data.id, :resource) : nil
-
-    eadid_url = ark_url.nil? ? data.ead_location : ark_url
-
     eadheader_atts = {:findaidstatus => data.finding_aid_status,
                       :repositoryencoding => "iso15511",
                       :countryencoding => "iso3166-1",
@@ -809,7 +539,7 @@
     xml.eadheader(eadheader_atts) {
 
       eadid_atts = {:countrycode => data.repo.country,
-              :url => eadid_url,
+                  :url => data.ead_location,
               :mainagencycode => data.mainagencycode}.reject {|k, v| v.nil? || v.empty? || v == "null" }
 
       xml.eadid(eadid_atts) {
@@ -827,7 +557,11 @@
           xml.titleproper("type" => "filing") { sanitize_mixed_content(data.finding_aid_filing_title, xml, fragments)} unless data.finding_aid_filing_title.nil?
           xml.titleproper { sanitize_mixed_content(titleproper, xml, fragments) }
           xml.subtitle {  sanitize_mixed_content(data.finding_aid_subtitle, xml, fragments) } unless data.finding_aid_subtitle.nil?
-          xml.author { sanitize_mixed_content(data.finding_aid_author, xml, fragments) }  unless data.finding_aid_author.nil?
+                      if data.finding_aid_author
+                        author = data.finding_aid_author
+                        author = customize_ead_data("Collection processed by ",author)
+                        xml.author { sanitize_mixed_content(author, xml, fragments) }
+                      end
           xml.sponsor { sanitize_mixed_content( data.finding_aid_sponsor, xml, fragments) } unless data.finding_aid_sponsor.nil?
 
         }
@@ -843,45 +577,21 @@
 
           if data.repo.image_url
             xml.p ( { "id" => "logostmt" } ) {
-                            xml.extref ({"xlink:href" => data.repo.image_url,
-                                        "xlink:actuate" => "onLoad",
-                                        "xlink:show" => "embed",
-                                        "xlink:type" => "simple"
+                          xml.extref ({"ns2:href" => data.repo.image_url,
+                            "ns2:actuate" => "onLoad",
+                            "ns2:show" => "embed",
+                            "ns2:type" => "simple"
                                         })
                           }
           end
-          if (data.finding_aid_date)
-            xml.p {
-                    val = data.finding_aid_date
-                    xml.date { sanitize_mixed_content( val, xml, fragments) }
-                  }
-          end
-
           unless data.addresslines.empty?
             xml.address {
               data.addresslines.each do |line|
                 xml.addressline { sanitize_mixed_content( line, xml, fragments) }
               end
-              if data.repo.url
-                xml.addressline ( "URL: " ) {
-                   xml.extptr ( {
-                           "xlink:href" => data.repo.url,
-                           "xlink:title" => data.repo.url,
-                           "xlink:type" => "simple",
-                           "xlink:show" => "new"
-                           } )
                  }
               end
             }
-          end
-
-          data.metadata_rights_declarations.each do |mrd|
-            if mrd["license"]
-              license_translation = I18n.t("enumerations.metadata_license.#{mrd['license']}", :default => mrd['license'])
-              xml.p (license_translation)
-            end
-          end
-        }
 
         if (data.finding_aid_series_statement)
           val = data.finding_aid_series_statement
@@ -897,21 +607,13 @@
       }
 
       xml.profiledesc {
-        creation = "This finding aid was produced using ArchivesSpace on <date>#{Time.now}</date>."
+                      # generates time as 2016-03-16T11:56-0400Z and the
+                      # gsub removes the 'Z'
+                      creation = "This finding aid was produced using ArchivesSpace <date>#{Time.now.utc.iso8601.gsub!('Z','')}</date>"
         xml.creation { sanitize_mixed_content( creation, xml, fragments) }
 
         if (val = data.finding_aid_language_note)
           xml.langusage (fragments << val)
-        else
-          xml.langusage() {
-            xml.text(I18n.t("resource.finding_aid_langusage_label"))
-            xml.language({langcode: "#{data.finding_aid_language}", :scriptcode => "#{data.finding_aid_script}"}) {
-              xml.text(I18n.t("enumerations.language_iso639_2.#{data.finding_aid_language}"))
-              xml.text(", ")
-              xml.text(I18n.t("enumerations.script_iso15924.#{data.finding_aid_script}"))
-              xml.text(" #{I18n.t("language_and_script.script").downcase}")}
-            xml.text(".")
-          }
         end
 
         if (val = data.descrules)
@@ -919,14 +621,13 @@
         end
       }
 
-      export_rs = @include_unpublished ? data.revision_statements : data.revision_statements.reject { |rs| !rs['publish'] }
-      if export_rs.length > 0
+                    if data.revision_statements.length > 0
         xml.revisiondesc {
-          export_rs.each do |rs|
+                        data.revision_statements.each do |rs|
             if rs['description'] && rs['description'].strip.start_with?('<')
               xml.text (fragments << rs['description'] )
             else
-              xml.change(rs['publish'] ? nil : {:audience => 'internal'}) {
+                            xml.change {
                 rev_date = rs['date'] ? rs['date'] : ""
                 xml.date (fragments <<  rev_date )
                 xml.item (fragments << rs['description']) if rs['description']
